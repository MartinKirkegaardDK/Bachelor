{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import load_everthing\n",
    "x,y = load_everthing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def make_split_dict(list_of_keys, test_size, val_size, seed = 1234):\n",
    "    \"\"\"Takes a list of keys, and the size of the test and val dataset as percentages\"\"\"\n",
    "    random.seed(seed)\n",
    "    d = dict()\n",
    "    test_size = 0.2\n",
    "    val_size = 0.1\n",
    "    total = len(list_of_keys)\n",
    "    all_keys = list_of_keys\n",
    "    test = int(total*test_size)\n",
    "    val = int(total*val_size)\n",
    "    test_keys = random.sample(all_keys, test)\n",
    "    all_keys = [i for i in all_keys if i not in test_keys]\n",
    "    val_keys = random.sample(all_keys, val)\n",
    "    all_keys = [i for i in all_keys if i not in val_keys]\n",
    "    d[\"train\"] = all_keys\n",
    "    d[\"test\"] = test_keys\n",
    "    d[\"val\"] = val_keys\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test_train_val_split(x,y,test_size, val_size):\n",
    "    new_x = defaultdict(lambda: defaultdict(dict))\n",
    "    #We just sample from CosDist. The reason is that we see no reason to sample independently from the different\n",
    "    #distance metrics, since the goal is simply to split the data up and compare the different distance metrics equally.\n",
    "    d = make_split_dict(list(x[\"CosDist\"].keys()), test_size, val_size)\n",
    "    for distance_metric, x_dict in x.items():\n",
    "        for iso, feature in x_dict.items():\n",
    "            if iso in d[\"train\"]:\n",
    "                new_x[\"train\"][distance_metric][iso] = feature\n",
    "            elif iso in d[\"test\"]:\n",
    "                new_x[\"test\"][distance_metric][iso] = feature\n",
    "            elif iso in d[\"val\"]:\n",
    "                new_x[\"val\"][distance_metric][iso] = feature\n",
    "    new_y = defaultdict(dict)\n",
    "    for iso, label in y.items():\n",
    "        if iso in d[\"train\"]:\n",
    "            new_y[\"train\"][iso] = label\n",
    "        if iso in d[\"test\"]:\n",
    "            new_y[\"test\"][iso] = label\n",
    "        if iso in d[\"val\"]:\n",
    "            new_y[\"val\"][iso] = label\n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x,new_y = test_train_val_split(x,y,0.2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
